{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Name: Thushal Babukumar ||  ID  : 46154469 || Portfolio-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting the Genre of Books from Summaries\n",
    "\n",
    "We'll use a set of book summaries from the [CMU Book Summaries Corpus](http://www.cs.cmu.edu/~dbamman/booksummaries.html) in this experiment.  This contains a large number of summaries (16,559) and includes meta-data about the genre of the books taken from Freebase.  Each book can have more than one genre and there are 227 genres listed in total.  To simplify the problem of genre prediction we will select a small number of target genres that occur frequently in the collection and select the books with these genre labels.  This will give us one genre label per book. \n",
    "\n",
    "Your goal in this portfolio is to take this data and build predictive models to classify the books into one of the five target genres.  You will need to extract suitable features from the texts and select suitable models to classify them. You should build and evaluate at least TWO models and compare the prediction results.\n",
    "\n",
    "You should report on each stage of your experiment as you work with the data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "The first task is to read the data. It is made available in tab-separated format but has no column headings. We can use `read_csv` to read this but we need to set the separator to `\\t` (tab) and supply the column names.  The names come from the [ReadMe](data/booksummaries/README.txt) file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wid</th>\n",
       "      <th>fid</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>genres</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>620</td>\n",
       "      <td>/m/0hhy</td>\n",
       "      <td>Animal Farm</td>\n",
       "      <td>George Orwell</td>\n",
       "      <td>1945-08-17</td>\n",
       "      <td>{\"/m/016lj8\": \"Roman \\u00e0 clef\", \"/m/06nbt\":...</td>\n",
       "      <td>Old Major, the old boar on the Manor Farm, ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>843</td>\n",
       "      <td>/m/0k36</td>\n",
       "      <td>A Clockwork Orange</td>\n",
       "      <td>Anthony Burgess</td>\n",
       "      <td>1962</td>\n",
       "      <td>{\"/m/06n90\": \"Science Fiction\", \"/m/0l67h\": \"N...</td>\n",
       "      <td>Alex, a teenager living in near-future Englan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>986</td>\n",
       "      <td>/m/0ldx</td>\n",
       "      <td>The Plague</td>\n",
       "      <td>Albert Camus</td>\n",
       "      <td>1947</td>\n",
       "      <td>{\"/m/02m4t\": \"Existentialism\", \"/m/02xlf\": \"Fi...</td>\n",
       "      <td>The text of The Plague is divided into five p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1756</td>\n",
       "      <td>/m/0sww</td>\n",
       "      <td>An Enquiry Concerning Human Understanding</td>\n",
       "      <td>David Hume</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>The argument of the Enquiry proceeds by a ser...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2080</td>\n",
       "      <td>/m/0wkt</td>\n",
       "      <td>A Fire Upon the Deep</td>\n",
       "      <td>Vernor Vinge</td>\n",
       "      <td></td>\n",
       "      <td>{\"/m/03lrw\": \"Hard science fiction\", \"/m/06n90...</td>\n",
       "      <td>The novel posits that space around the Milky ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    wid      fid                                      title           author  \\\n",
       "0   620  /m/0hhy                                Animal Farm    George Orwell   \n",
       "1   843  /m/0k36                         A Clockwork Orange  Anthony Burgess   \n",
       "2   986  /m/0ldx                                 The Plague     Albert Camus   \n",
       "3  1756  /m/0sww  An Enquiry Concerning Human Understanding       David Hume   \n",
       "4  2080  /m/0wkt                       A Fire Upon the Deep     Vernor Vinge   \n",
       "\n",
       "         date                                             genres  \\\n",
       "0  1945-08-17  {\"/m/016lj8\": \"Roman \\u00e0 clef\", \"/m/06nbt\":...   \n",
       "1        1962  {\"/m/06n90\": \"Science Fiction\", \"/m/0l67h\": \"N...   \n",
       "2        1947  {\"/m/02m4t\": \"Existentialism\", \"/m/02xlf\": \"Fi...   \n",
       "3                                                                  \n",
       "4              {\"/m/03lrw\": \"Hard science fiction\", \"/m/06n90...   \n",
       "\n",
       "                                             summary  \n",
       "0   Old Major, the old boar on the Manor Farm, ca...  \n",
       "1   Alex, a teenager living in near-future Englan...  \n",
       "2   The text of The Plague is divided into five p...  \n",
       "3   The argument of the Enquiry proceeds by a ser...  \n",
       "4   The novel posits that space around the Milky ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = ['wid', 'fid', 'title', 'author', 'date', 'genres', 'summary']\n",
    "\n",
    "books = pd.read_csv(\"data/booksummaries/booksummaries.txt\", sep=\"\\t\", header=None, names=names, keep_default_na=False)\n",
    "books.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We next filter the data so that only our target genre labels are included and we assign each text to just one of the genre labels.  It's possible that one text could be labelled with two of these labels (eg. Science Fiction and Fantasy) but we will just assign one of those here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8954, 5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_genres = [\"Children's literature\",\n",
    "                 'Science Fiction',\n",
    "                 'Novel',\n",
    "                 'Fantasy',\n",
    "                 'Mystery']\n",
    "\n",
    "# create a Series of empty strings the same length as the list of books\n",
    "genre = pd.Series(np.repeat(\"\", books.shape[0]))\n",
    "# look for each target genre and set the corresponding entries in the genre series to the genre label\n",
    "for g in target_genres:\n",
    "    genre[books['genres'].str.contains(g)] = g\n",
    "\n",
    "# add this to the book dataframe and then select only those rows that have a genre label\n",
    "# drop some useless columns\n",
    "books['genre'] = genre\n",
    "genre_books = books[genre!=''].drop(['genres', 'fid', 'wid'], axis=1)\n",
    "\n",
    "genre_books.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>genre</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Children's literature</th>\n",
       "      <td>1092</td>\n",
       "      <td>1092</td>\n",
       "      <td>1092</td>\n",
       "      <td>1092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fantasy</th>\n",
       "      <td>2311</td>\n",
       "      <td>2311</td>\n",
       "      <td>2311</td>\n",
       "      <td>2311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mystery</th>\n",
       "      <td>1396</td>\n",
       "      <td>1396</td>\n",
       "      <td>1396</td>\n",
       "      <td>1396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Novel</th>\n",
       "      <td>2258</td>\n",
       "      <td>2258</td>\n",
       "      <td>2258</td>\n",
       "      <td>2258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Science Fiction</th>\n",
       "      <td>1897</td>\n",
       "      <td>1897</td>\n",
       "      <td>1897</td>\n",
       "      <td>1897</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       title  author  date  summary\n",
       "genre                                              \n",
       "Children's literature   1092    1092  1092     1092\n",
       "Fantasy                 2311    2311  2311     2311\n",
       "Mystery                 1396    1396  1396     1396\n",
       "Novel                   2258    2258  2258     2258\n",
       "Science Fiction         1897    1897  1897     1897"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check how many books we have in each genre category\n",
    "genre_books.groupby('genre').count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>summary</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Animal Farm</td>\n",
       "      <td>George Orwell</td>\n",
       "      <td>1945-08-17</td>\n",
       "      <td>Old Major, the old boar on the Manor Farm, ca...</td>\n",
       "      <td>Children's literature</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A Clockwork Orange</td>\n",
       "      <td>Anthony Burgess</td>\n",
       "      <td>1962</td>\n",
       "      <td>Alex, a teenager living in near-future Englan...</td>\n",
       "      <td>Novel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Plague</td>\n",
       "      <td>Albert Camus</td>\n",
       "      <td>1947</td>\n",
       "      <td>The text of The Plague is divided into five p...</td>\n",
       "      <td>Novel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A Fire Upon the Deep</td>\n",
       "      <td>Vernor Vinge</td>\n",
       "      <td></td>\n",
       "      <td>The novel posits that space around the Milky ...</td>\n",
       "      <td>Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A Wizard of Earthsea</td>\n",
       "      <td>Ursula K. Le Guin</td>\n",
       "      <td>1968</td>\n",
       "      <td>Ged is a young boy on Gont, one of the larger...</td>\n",
       "      <td>Fantasy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  title             author        date  \\\n",
       "0           Animal Farm      George Orwell  1945-08-17   \n",
       "1    A Clockwork Orange    Anthony Burgess        1962   \n",
       "2            The Plague       Albert Camus        1947   \n",
       "4  A Fire Upon the Deep       Vernor Vinge               \n",
       "6  A Wizard of Earthsea  Ursula K. Le Guin        1968   \n",
       "\n",
       "                                             summary                  genre  \n",
       "0   Old Major, the old boar on the Manor Farm, ca...  Children's literature  \n",
       "1   Alex, a teenager living in near-future Englan...                  Novel  \n",
       "2   The text of The Plague is divided into five p...                  Novel  \n",
       "4   The novel posits that space around the Milky ...                Fantasy  \n",
       "6   Ged is a young boy on Gont, one of the larger...                Fantasy  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre_books.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Exaction\n",
    "\n",
    "Now you take over to build a suitable model and present your results.\n",
    "\n",
    "Firstly, you need to perform feature extraction to produce feature vectors for the predictive models.\n",
    "\n",
    "We are not adding stop words to our feature list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of features selected:  5000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "vectorizer  = TfidfVectorizer(max_features = 5000, stop_words= stopwords.words('english'), min_df=5)\n",
    "X = vectorizer.fit_transform(genre_books.summary).toarray()\n",
    "print('No. of features selected: ', len(vectorizer.get_feature_names()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Encoding\n",
    "\n",
    "We are encoding each genre with a numerical value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded values for each genre:  {0, 1, 2, 3, 4}\n"
     ]
    }
   ],
   "source": [
    "#Encoding each genre with a numerical value\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(genre_books.genre)\n",
    "genre_books['label'] = le.transform(genre_books.genre)\n",
    "print(\"Encoded values for each genre: \",set(genre_books.label) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Children's literature\", 'Fantasy', 'Mystery', 'Novel', 'Science Fiction']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Decoding the encoded values\n",
    "target_names = list(le.inverse_transform([0,1,2,3,4]))\n",
    "target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>summary</th>\n",
       "      <th>genre</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Animal Farm</td>\n",
       "      <td>George Orwell</td>\n",
       "      <td>1945-08-17</td>\n",
       "      <td>Old Major, the old boar on the Manor Farm, ca...</td>\n",
       "      <td>Children's literature</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A Clockwork Orange</td>\n",
       "      <td>Anthony Burgess</td>\n",
       "      <td>1962</td>\n",
       "      <td>Alex, a teenager living in near-future Englan...</td>\n",
       "      <td>Novel</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Plague</td>\n",
       "      <td>Albert Camus</td>\n",
       "      <td>1947</td>\n",
       "      <td>The text of The Plague is divided into five p...</td>\n",
       "      <td>Novel</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A Fire Upon the Deep</td>\n",
       "      <td>Vernor Vinge</td>\n",
       "      <td></td>\n",
       "      <td>The novel posits that space around the Milky ...</td>\n",
       "      <td>Fantasy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A Wizard of Earthsea</td>\n",
       "      <td>Ursula K. Le Guin</td>\n",
       "      <td>1968</td>\n",
       "      <td>Ged is a young boy on Gont, one of the larger...</td>\n",
       "      <td>Fantasy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  title             author        date  \\\n",
       "0           Animal Farm      George Orwell  1945-08-17   \n",
       "1    A Clockwork Orange    Anthony Burgess        1962   \n",
       "2            The Plague       Albert Camus        1947   \n",
       "4  A Fire Upon the Deep       Vernor Vinge               \n",
       "6  A Wizard of Earthsea  Ursula K. Le Guin        1968   \n",
       "\n",
       "                                             summary                  genre  \\\n",
       "0   Old Major, the old boar on the Manor Farm, ca...  Children's literature   \n",
       "1   Alex, a teenager living in near-future Englan...                  Novel   \n",
       "2   The text of The Plague is divided into five p...                  Novel   \n",
       "4   The novel posits that space around the Milky ...                Fantasy   \n",
       "6   Ged is a young boy on Gont, one of the larger...                Fantasy   \n",
       "\n",
       "   label  \n",
       "0      0  \n",
       "1      3  \n",
       "2      3  \n",
       "4      1  \n",
       "6      1  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre_books.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "\n",
    "Then, train two predictive models from the given data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7163, 5000)\n",
      "(1791, 5000)\n",
      "(7163,)\n",
      "(1791,)\n"
     ]
    }
   ],
   "source": [
    "#splitting our data in training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, genre_books['label'], test_size = 0.2, random_state = 143)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building various ML models and printing their performance scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Logistic Regression*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_test_pred = lr.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       precision    recall  f1-score   support\n",
      "\n",
      "Children's literature       0.67      0.47      0.55       242\n",
      "              Fantasy       0.76      0.75      0.75       485\n",
      "              Mystery       0.77      0.68      0.72       274\n",
      "                Novel       0.59      0.75      0.66       427\n",
      "      Science Fiction       0.75      0.74      0.74       363\n",
      "\n",
      "             accuracy                           0.70      1791\n",
      "            macro avg       0.71      0.68      0.69      1791\n",
      "         weighted avg       0.71      0.70      0.70      1791\n",
      "\n"
     ]
    }
   ],
   "source": [
    "average_acc_LR = accuracy_score(y_test, y_test_pred)\n",
    "average_prec_LR = precision_score(y_test, y_test_pred, average='weighted')\n",
    "average_recall_LR = recall_score(y_test, y_test_pred, average='weighted')\n",
    "average_f1_LR = f1_score(y_test, y_test_pred, average='weighted')\n",
    "print(classification_report(y_test, y_test_pred, target_names= target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *K nearest neighbor* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=3)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neigh = KNeighborsClassifier(n_neighbors = 3)\n",
    "neigh.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_y_test_pred = neigh.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       precision    recall  f1-score   support\n",
      "\n",
      "Children's literature       0.36      0.16      0.22       242\n",
      "              Fantasy       0.29      0.94      0.45       485\n",
      "              Mystery       0.77      0.13      0.22       274\n",
      "                Novel       0.61      0.06      0.11       427\n",
      "      Science Fiction       0.81      0.10      0.19       363\n",
      "\n",
      "             accuracy                           0.33      1791\n",
      "            macro avg       0.57      0.28      0.24      1791\n",
      "         weighted avg       0.55      0.33      0.25      1791\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, knn_y_test_pred, target_names= target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "average_acc_knn = accuracy_score(y_test, knn_y_test_pred)\n",
    "average_prec_knn = precision_score(y_test, knn_y_test_pred, average='weighted')\n",
    "average_f1_knn = f1_score(y_test, knn_y_test_pred, average='weighted')\n",
    "average_recall_knn = recall_score(y_test, knn_y_test_pred, average='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *SVC Model*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('svc', SVC(gamma='auto'))])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "clf = make_pipeline(StandardScaler(), SVC(gamma='auto'))\n",
    "clf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_SVM_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       precision    recall  f1-score   support\n",
      "\n",
      "Children's literature       0.67      0.25      0.36       242\n",
      "              Fantasy       0.76      0.74      0.75       485\n",
      "              Mystery       0.83      0.54      0.65       274\n",
      "                Novel       0.50      0.81      0.62       427\n",
      "      Science Fiction       0.73      0.71      0.72       363\n",
      "\n",
      "             accuracy                           0.65      1791\n",
      "            macro avg       0.70      0.61      0.62      1791\n",
      "         weighted avg       0.69      0.65      0.65      1791\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_SVM_pred, target_names= target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "average_acc_svm = accuracy_score(y_test, y_SVM_pred)\n",
    "average_prec_svm = precision_score(y_test, y_SVM_pred, average='weighted')\n",
    "average_recall_svm = recall_score(y_test, y_SVM_pred, average='weighted')\n",
    "average_f1_svm = f1_score(y_test, y_SVM_pred, average='weighted')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Random Forest*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=5, n_estimators=20, n_jobs=100, random_state=0)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "clf = RandomForestClassifier(max_depth=5,random_state=0, n_estimators=20, n_jobs=100, )\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_rf_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       precision    recall  f1-score   support\n",
      "\n",
      "Children's literature       0.00      0.00      0.00       242\n",
      "              Fantasy       0.60      0.62      0.61       485\n",
      "              Mystery       0.86      0.12      0.21       274\n",
      "                Novel       0.35      0.82      0.49       427\n",
      "      Science Fiction       0.70      0.46      0.56       363\n",
      "\n",
      "             accuracy                           0.48      1791\n",
      "            macro avg       0.50      0.41      0.37      1791\n",
      "         weighted avg       0.52      0.48      0.43      1791\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_rf_pred, target_names= target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "average_acc_rf = accuracy_score(y_test, y_rf_pred)\n",
    "average_prec_rf = precision_score(y_test, y_rf_pred, average='weighted')\n",
    "average_recall_rf = recall_score(y_test, y_rf_pred, average='weighted')\n",
    "average_f1_rf = f1_score(y_test, y_rf_pred, average='weighted')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  *Decision Tree*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(random_state=0)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier(random_state=0)\n",
    "clf.fit(X_train, y_train, sample_weight=None, check_input=True, X_idx_sorted=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_dt_test = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       precision    recall  f1-score   support\n",
      "\n",
      "Children's literature       0.31      0.29      0.30       242\n",
      "              Fantasy       0.54      0.51      0.53       485\n",
      "              Mystery       0.48      0.53      0.51       274\n",
      "                Novel       0.43      0.47      0.45       427\n",
      "      Science Fiction       0.52      0.49      0.50       363\n",
      "\n",
      "             accuracy                           0.47      1791\n",
      "            macro avg       0.46      0.46      0.46      1791\n",
      "         weighted avg       0.47      0.47      0.47      1791\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_dt_test, target_names= target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "average_acc_dt = accuracy_score(y_test, y_dt_test)\n",
    "average_prec_dt = precision_score(y_test, y_dt_test, average='weighted')\n",
    "average_recall_dt = recall_score(y_test, y_dt_test, average='weighted')\n",
    "average_f1_dt = f1_score(y_test, y_dt_test, average='weighted')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Neural Network*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "clf = MLPClassifier(random_state=1, max_iter=300).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_nn_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       precision    recall  f1-score   support\n",
      "\n",
      "Children's literature       0.60      0.52      0.56       242\n",
      "              Fantasy       0.71      0.71      0.71       485\n",
      "              Mystery       0.66      0.65      0.65       274\n",
      "                Novel       0.60      0.62      0.61       427\n",
      "      Science Fiction       0.63      0.66      0.65       363\n",
      "\n",
      "             accuracy                           0.65      1791\n",
      "            macro avg       0.64      0.63      0.64      1791\n",
      "         weighted avg       0.65      0.65      0.64      1791\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_nn_pred, target_names= target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "average_acc_nn = accuracy_score(y_test, y_nn_pred)\n",
    "average_prec_nn = precision_score(y_test, y_nn_pred, average='weighted')\n",
    "average_recall_nn = recall_score(y_test, y_nn_pred, average='weighted')\n",
    "average_f1_nn = f1_score(y_test, y_nn_pred, average='weighted')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Adaboost classifier*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(n_estimators=100, random_state=0)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " from sklearn.ensemble import AdaBoostClassifier\n",
    "clf = AdaBoostClassifier(n_estimators=100, random_state=0)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ada_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       precision    recall  f1-score   support\n",
      "\n",
      "Children's literature       0.51      0.45      0.48       242\n",
      "              Fantasy       0.70      0.63      0.66       485\n",
      "              Mystery       0.65      0.59      0.62       274\n",
      "                Novel       0.49      0.60      0.54       427\n",
      "      Science Fiction       0.66      0.67      0.66       363\n",
      "\n",
      "             accuracy                           0.60      1791\n",
      "            macro avg       0.60      0.59      0.59      1791\n",
      "         weighted avg       0.61      0.60      0.60      1791\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_ada_pred, target_names= target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "average_acc_ada = accuracy_score(y_test, y_ada_pred)\n",
    "average_prec_ada = precision_score(y_test, y_ada_pred, average='weighted')\n",
    "average_recall_ada = recall_score(y_test, y_ada_pred, average='weighted')\n",
    "average_f1_ada = f1_score(y_test, y_ada_pred, average='weighted')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Naive Bayes Algorithm*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf = GaussianNB()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_nb_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       precision    recall  f1-score   support\n",
      "\n",
      "Children's literature       0.41      0.46      0.43       242\n",
      "              Fantasy       0.77      0.61      0.68       485\n",
      "              Mystery       0.50      0.54      0.52       274\n",
      "                Novel       0.47      0.47      0.47       427\n",
      "      Science Fiction       0.56      0.64      0.60       363\n",
      "\n",
      "             accuracy                           0.55      1791\n",
      "            macro avg       0.54      0.54      0.54      1791\n",
      "         weighted avg       0.57      0.55      0.56      1791\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_nb_pred, target_names= target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "average_acc_nb = accuracy_score(y_test, y_nb_pred)\n",
    "average_prec_nb = precision_score(y_test, y_nb_pred, average='weighted')\n",
    "average_recall_nb = recall_score(y_test, y_nb_pred, average='weighted')\n",
    "average_f1_nb = f1_score(y_test, y_nb_pred, average='weighted')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a matrix of all the prediction scores of various models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = [[average_acc_LR, average_acc_knn, average_acc_svm,average_acc_rf, average_acc_dt, average_acc_nn, average_acc_ada, average_acc_nb ],[average_prec_LR, average_prec_knn, average_acc_svm,average_acc_rf,average_acc_dt, average_acc_nn, average_acc_ada, average_acc_nb ] , [average_f1_LR, average_f1_knn, average_f1_svm,average_f1_rf, average_f1_dt, average_f1_nn, average_f1_ada, average_f1_nb ]\n",
    "       , [average_recall_LR, average_recall_knn, average_recall_svm,average_recall_rf, average_recall_dt, average_recall_nn, average_recall_ada, average_recall_nb]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation\n",
    "\n",
    "Finally, we evaluate and compare the learned predictive models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pos = list(range(len(data[0])))\n",
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "plt.bar(pos, data[0], width, alpha=0.5, color='r')\n",
    "plt.bar([p + width for p in pos], data[1], width, alpha=0.5, color='b')\n",
    "plt.bar([p + width*2 for p in pos], data[2], width, alpha=0.5, color='g')\n",
    "plt.bar([p + width*3 for p in pos], data[3], width, alpha=0.5, color='y')\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "# Setting the y axis label\n",
    "ax.set_ylabel('Score')\n",
    "\n",
    "# Setting the chart's title\n",
    "ax.set_title('Test Subject Scores')\n",
    "\n",
    "# Setting the position of the x ticks\n",
    "ax.set_xticks([p + 1.5 * width for p in pos])\n",
    "\n",
    "# Setting the labels for the x ticks\n",
    "ax.set_xticklabels(labels)\n",
    "\n",
    "# Setting the x-axis and y-axis limits\n",
    "plt.xlim(min(pos)-width, max(pos)+width*4)\n",
    "plt.ylim([0, max(data[0]+ data[1]+data[2]+data[3])*1.5] )\n",
    "\n",
    "# Adding the legend and showing the plot\n",
    "plt.legend(['accuracy', 'precision', 'f1','recall'], loc='upper right')\n",
    "plt.grid(None)\n",
    "plt.show()\n",
    "\n",
    "#https://www.dezyre.com/recipes/generate-grouped-bar-plot-in-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "### - From the final comparison graph we see that Logistic Prediction has the highest prediction scores out of all the models we have built\n",
    "\n",
    "### - The reason behind this might be because the other models have been used with the default parameters and have not been fine tuned for the best performance. For example, the 'n' value for K nearest neighbors was chosen randomly and no analysis was performed to choose the best value of 'n'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
